import pandas as pd
from bs4 import BeautifulSoup
from io import StringIO
import time
import shutil  

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

def obtener_stats_nfl_live():
    url = "https://www.pro-football-reference.com/years/2025/passing.htm"
    
    # --- 1. CONFIGURACI√ìN DEL NAVEGADOR (HEADLESS) ---
    # Estas opciones son cr√≠ticas para evitar crasheos en entornos de servidor (Docker/Streamlit)
    options = Options()
    options.add_argument("--headless") # Ejecuta sin interfaz gr√°fica (m√°s r√°pido y compatible)
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080") 
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

    # --- 2. DETECCI√ìN DE ENTORNO (H√çBRIDO) ---
    # L√≥gica inteligente para alternar entre entorno Local (WebDriverManager) y Nube (Binarios de Linux).
    # Esto permite que el mismo c√≥digo funcione en mi Mac y en el servidor de Streamlit sin cambios.
    chromium_path = shutil.which("chromium") or shutil.which("chromium-browser")
    chromedriver_path = shutil.which("chromedriver")

    if chromium_path and chromedriver_path:
        print(f"‚òÅÔ∏è Usando configuraci√≥n de Nube (Linux detectado)")
        options.binary_location = chromium_path
        service = Service(executable_path=chromedriver_path)
    else:
        print("üíª Usando configuraci√≥n Local (Mac/Windows)")
        service = Service(ChromeDriverManager().install())

    # --- 3. EXTRACCI√ìN DE DATOS (SCRAPING) ---
    try:
        driver = webdriver.Chrome(service=service, options=options)
        driver.get(url)
        
        # Espera expl√≠cita para asegurar carga de JS si fuera necesario
        time.sleep(3)
        html_vivo = driver.page_source
        driver.quit() # Cerramos navegador para liberar memoria RAM
        
    except Exception as e:
        print(f"‚ùå Error cr√≠tico iniciando Selenium: {e}")
        return None

    print("Info capturada. Procesando con Pandas...")
    
    # --- 4. PARSEO Y LIMPIEZA (PANDAS & BS4) ---
    # Usamos BeautifulSoup para aislar la tabla antes de pasarla a Pandas (m√°s robusto)
    soup = BeautifulSoup(html_vivo, 'html.parser')
    tabla = soup.find('table', id='passing')

    if not tabla:
        print("‚ùå No se encontr√≥ la tabla de estad√≠sticas.")
        return None

    html_en_memoria = StringIO(str(tabla))
    dfs = pd.read_html(html_en_memoria)
    df = dfs[0]

    # Limpieza de Headers: Si hay multi-index, lo aplanamos
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = df.columns.droplevel(0)
        
    # Filtrado de basura: Eliminamos las filas repetidas que usa la web como separadores
    df = df[df['Rk'] != 'Rk']
    
    # Normalizaci√≥n de nombres
    if 'Tm' not in df.columns and 'Team' in df.columns:
        df.rename(columns={'Team': 'Tm'}, inplace=True)

    # Limpieza de strings: Quitamos caracteres especiales de los nombres (*, +)
    df['Player'] = df['Player'].str.replace('*', '', regex=False)
    df['Player'] = df['Player'].str.replace('+', '', regex=False)

    # Selecci√≥n de columnas relevantes para el dashboard
    columnas_clave = ['Player', 'G', 'Tm', 'Yds', 'TD', 'Int', 'Rate']
    cols_existentes = [c for c in columnas_clave if c in df.columns]
    df_final = df[cols_existentes].copy()

    # Conversi√≥n de tipos: De string a numeric para poder ordenar y graficar
    cols_numericas = ['G','Yds', 'TD', 'Int', 'Rate']
    for col in cols_numericas:
        if col in df_final.columns:
            df_final[col] = pd.to_numeric(df_final[col])

    # Ordenamiento final
    if 'Yds' in df_final.columns:
        df_final = df_final.sort_values(by='Yds', ascending=False).reset_index(drop=True)
    
    return df_final

# --- EJECUCI√ìN PRINCIPAL ---
if __name__ == '__main__':
    stats = obtener_stats_nfl_live()
    
    if stats is not None:
        print("\nüèÜ TOP 5 L√çDERES EN YARDAS (EN VIVO):")
        print(stats.head(5))
        stats.to_csv('nfl_data_live.csv', index=False)
        print("\n‚úÖ Datos guardados exitosamente.")